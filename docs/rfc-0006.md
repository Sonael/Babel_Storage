# RFC 0006: Extensões Futuras e Roteiro

**Status**: Rascunho
**Versão**: Futura (pós-v5)
**Data**: 2026-02-16
**Autor**: Sonael de Albuquerque Angelos Neto.

## Resumo

Este documento descreve as extensões e melhorias planejadas para o Protocolo BabelStorage além do BSP v5. Essas propostas abordam preocupações de escalabilidade, desempenho, segurança e usabilidade identificadas durante o uso no mundo real.

## 1. Extensões Propostas

### 1.1 Árvore Merkle para Verificação de Integridade por Subconjunto (BSP v6)

**Problema**: A verificação de arquivos grandes requer o download de todos os chunks.

**Solução**: Adicionar a raiz da árvore Merkle aos metadados para verificação de integridade de subconjuntos de chunks.

**Benefícios:**
*   Verificar a integridade de subconjuntos de chunks sem download completo
*   Provar que um chunk específico não foi adulterado sem recuperar todos os chunks
*   Permitir sincronização delta eficiente

**Limitação importante — incompatibilidade com compressão monolítica**: A árvore Merkle permite provar a integridade de um chunk isolado, mas não permite descomprimi-lo de forma independente quando o arquivo utiliza compressão Zstandard monolítica (conforme RFC 0002). O Zstandard mantém estado entre blocos: para descomprimir o chunk N, é necessário ter processado os chunks 0 a N-1. Portanto, esta extensão habilita **verificação de integridade parcial**, mas não **download seletivo com descompressão isolada**.

Para habilitar descompressão isolada de chunks, seria necessário comprimir cada chunk de forma independente, com impacto na taxa de compressão (redução estimada de 30-50% em eficiência). Este trade-off deve ser avaliado e especificado antes da implementação.

**Alterações nos Metadados:**
```json
{
  "f": "large_file.dat",
  "h": "file_sha256...",
  "merkle_root": "tree_root_sha256...",
  "merkle_height": 6,
  "chk": [...]
}
```

**Implementação:**
```python
def build_merkle_tree(chunks: List[bytes]) -> str:
    """Constrói a árvore Merkle e retorna o hash da raiz."""
    leaves = [hashlib.sha256(chunk).digest() for chunk in chunks]
    
    while len(leaves) > 1:
        parents = []
        for i in range(0, len(leaves), 2):
            left = leaves[i]
            right = leaves[i+1] if i+1 < len(leaves) else left
            parent = hashlib.sha256(left + right).digest()
            parents.append(parent)
        leaves = parents
    
    return leaves[0].hex()
```

**Prioridade**: Alta
**Esforço Estimado**: Médio
**Alvo**: BSP v6 (Q3 2026)

---

### 1.2 Upload Paralelo de Chunks (Desempenho)

**Problema**: O upload sequencial é lento para arquivos grandes.

**Solução**: Fazer upload de múltiplos chunks concorrentemente com limitação de taxa.

**Implementação:**
```python
import asyncio
import aiohttp

async def upload_chunk_async(chunk_index, chunk_data, semaphore):
    """Faz upload de um único chunk com controle de concorrência."""
    async with semaphore:
        # Limitação de taxa
        await asyncio.sleep(1.5)
        
        # Codificar
        encoded = binary_encoder.encode_bytes_to_babel(chunk_data)
        
        # Buscar (HTTP assíncrono)
        async with aiohttp.ClientSession() as session:
            coords = await babel_async.search(session, encoded)
        
        return chunk_index, coords

async def upload_file_parallel(chunks, max_concurrent=5):
    """Faz upload de chunks em paralelo."""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    tasks = [
        upload_chunk_async(i, chunk, semaphore)
        for i, chunk in enumerate(chunks)
    ]
    
    results = await asyncio.gather(*tasks)
    return results
```

**Benefícios:**
*   Uploads 3-5× mais rápidos (com limitação de taxa)
*   Melhor utilização da rede
*   Progresso mostrado por chunk

**Prioridade**: Alta
**Esforço Estimado**: Médio
**Alvo**: v1.1 (Q1 2026)

---

### 1.3 Criptografia do Lado do Cliente (Privacidade)

**Problema**: O conteúdo da Biblioteca de Babel é público.

**Solução**: Criptografar arquivos antes do upload usando AES-256-GCM.

**Fluxo de Trabalho:**
```
Arquivo Original → [Criptografar com AES-256-GCM] → Arquivo Criptografado → [Upload para Babel]
                         ↓
                 Chave de Criptografia (usuário mantém)
```

**Metadados:**
```json
{
  "f": "document.pdf.enc",
  "encryption": {
    "algorithm": "AES-256-GCM",
    "key_derivation": "PBKDF2-SHA256",
    "iterations": 100000,
    "salt": "base64_salt",
    "nonce": "base64_nonce",
    "tag": "base64_auth_tag"
  },
  "original_filename": "document.pdf",
  "chk": [...]
}
```

**CLI:**
```bash
# Upload com criptografia
python babel_storage.py upload document.pdf \
  --metadata document.json.gz \
  --encrypt \
  --password "strong_passphrase"

# Download com descriptografia
python babel_storage.py download document.json.gz \
  --output document.pdf \
  --password "strong_passphrase"
```

**Prioridade**: Média
**Esforço Estimado**: Alto
**Alvo**: v1.2 (Q2 2026)

---

### 1.4 Retomar Uploads Interrompidos

**Problema**: Falhas de rede abortam o upload inteiro.

**Solução**: Salvar o progresso e retomar do último chunk bem-sucedido.

**Implementação:**
```json
{
  "upload_id": "abc123...",
  "file_path": "document.pdf",
  "metadata_path": "document.json.gz",
  "completed_chunks": [0, 1, 2, 5, 7],
  "total_chunks": 38,
  "timestamp": "2026-02-16T10:30:00Z"
}

# Comando de retomada
python babel_storage.py resume upload_progress.json
```

**Prioridade**: Alta
**Esforço Estimado**: Baixo
**Alvo**: v1.1 (Q1 2026)

---

### 1.5 Deduplicação Entre Usuários

**Problema**: O mesmo arquivo enviado várias vezes desperdiça esforço.

**Solução**: Armazenamento de metadados endereçáveis por conteúdo com coordenadas compartilhadas.

**Conceito:**
```
Hash do Arquivo → Registro de Metadados Compartilhados → Coordenadas
                                           ↓
                          Múltiplos usuários referenciam as mesmas coordenadas
```

**Desafios:**
*   Mecanismo de coordenação necessário
*   Modelo de confiança para metadados compartilhados
*   Preocupações com privacidade

**Prioridade**: Baixa
**Esforço Estimado**: Muito Alto
**Alvo**: v2.0 (2027)

---

### 1.6 Algoritmos de Codificação Alternativos

**Problema**: Base-29 tem sobrecarga de 1.647×.

**Solução**: Suportar múltiplos esquemas de codificação:

| Codificação | Tamanho do Alfabeto | Sobrecarga | Notas |
|-------------|---------------------|------------|-------|
| Base-29 (atual) | 29 | 1.647× | Compatível com Babel |
| Base-85 | 85 | 1.25× | Mais eficiente |
| Base-95 | 95 | 1.23× | Mais eficiente |

**Metadados:**
```json
{
  "encoding": {
    "algorithm": "base29",
    "version": "v4"
  }
}
```

**Prioridade**: Baixa
**Esforço Estimado**: Médio
**Alvo**: v2.0

---

### 1.7 Escolha do Algoritmo de Compressão

**Problema**: Zstandard nível 19 é lento.

**Solução**: Permitir que o usuário escolha a compressão:

```bash
python babel_storage.py upload file.dat \
  --compression zstd:3  # Mais rápido, menos compressão
  
python babel_storage.py upload file.dat \
  --compression zstd:19  # Mais lento, mais compressão (padrão)
  
python babel_storage.py upload file.txt \
  --compression none  # Sem compressão (já comprimido)
```

**Prioridade**: Média
**Esforço Estimado**: Baixo
**Alvo**: v1.1

---

### 1.8 Melhorias na UI Web

**Recursos Propostos:**
*   Arrastar e soltar múltiplos arquivos
*   Operações em lote (excluir múltiplos)
*   Otimização da velocidade de download
*   Links de compartilhamento com expiração
*   Visualização de arquivos (imagens, PDFs)
*   Painel de estatísticas de uso

**Prioridade**: Média
**Esforço Estimado**: Médio
**Alvo**: v1.2

---

### 1.9 Contêiner Docker

**Objetivo**: Implantação simplificada.

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .

RUN pip install -r requirements.txt

EXPOSE 5000

CMD ["python", "app.py"]
```

```bash
docker build -t babelstorage .
docker run -p 5000:5000 -v ./metadata:/app/metadata babelstorage
```

**Prioridade**: Média
**Esforço Estimado**: Baixo
**Alvo**: v1.1

---

### 1.10 Backends de Armazenamento Alternativos

**Objetivo**: Suportar outros sistemas de armazenamento "infinitos".

**Candidatos:**
*   IPFS (InterPlanetary File System)
*   Arweave (blockchain de armazenamento permanente)
*   Filecoin (rede de armazenamento descentralizada)
*   Pi Network (armazenamento infinito hipotético)

**Arquitetura:**
```python
class StorageBackend(ABC):
    @abstractmethod
    def search(self, encoded: str) -> Coordinates:
        pass
    
    @abstractmethod
    def retrieve(self, coords: Coordinates) -> str:
        pass

class BabelBackend(StorageBackend):
    # Implementação atual
    pass

class IPFSBackend(StorageBackend):
    # Implementação IPFS
    pass
```

**Prioridade**: Baixa
**Esforço Estimado**: Muito Alto
**Alvo**: v2.0

---

## 2. Resumo do Roteiro

### v1.1 (Q2 2026) - Desempenho e Estabilidade
*   [ ] Upload paralelo de chunks
*   [ ] Retomar uploads interrompidos
*   [ ] Contêiner Docker
*   [ ] Escolha de compressão
*   [ ] Suíte de testes abrangente

### v1.2 (Q3 2026) - Recursos e UX
*   [ ] Criptografia do lado do cliente
*   [ ] Verificação de árvore Merkle (BSP v6)
*   [ ] Melhorias na UI Web
*   [ ] Automação de backup de metadados

### v2.0 (2027) - Arquitetura e Escala
*   [ ] Backends de armazenamento alternativos
*   [ ] Sistema de deduplicação
*   [ ] Esquemas de codificação alternativos
*   [ ] Recursos empresariais (cotas, logs de auditoria)

---

## 3. Referências

*   [RFC 0001](rfc-0001.md) - Integridade no Nível do Arquivo
*   [RFC 0002](rfc-0002.md) - Checksums por Chunk
*   [RFC 0003](rfc-0003.md) - Codificação Binária
*   [RFC 0004](rfc-0004.md) - Assinatura de Metadados
*   [RFC 0005](rfc-0005.md) - Modo Estrito

---

**Direitos Autorais**: Licença MIT